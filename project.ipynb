{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEUP - AC\n",
    "## Banking - Predicting a Loan Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business understanding\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis\n",
    "\n",
    "Let us start by importing the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     loan_id  account_id    date  amount  duration  payments  status\n",
      "0       5314        1787  930705   96396        12      8033      -1\n",
      "1       5316        1801  930711  165960        36      4610       1\n",
      "2       6863        9188  930728  127080        60      2118       1\n",
      "3       5325        1843  930803  105804        36      2939       1\n",
      "4       7240       11013  930906  274740        60      4579       1\n",
      "..       ...         ...     ...     ...       ...       ...     ...\n",
      "323     6818        9030  961212  155616        48      3242       1\n",
      "324     5625        3189  961215  222180        60      3703      -1\n",
      "325     6805        8972  961221   45024        48       938       1\n",
      "326     7233       10963  961225  115812        36      3217       1\n",
      "327     7308       11362  961227  129408        24      5392       1\n",
      "\n",
      "[328 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaoj\\AppData\\Local\\Temp\\ipykernel_16464\\3455949170.py:13: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  transactions = pd.read_csv(DATA_SOURCE + 'trans_dev.csv', sep=';')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_SOURCE = 'data/'\n",
    "\n",
    "# Read in the data\n",
    "accounts = pd.read_csv(DATA_SOURCE + 'account.csv', sep=';')\n",
    "cards = pd.read_csv(DATA_SOURCE + 'card_dev.csv', sep=';')\n",
    "clients = pd.read_csv(DATA_SOURCE + 'client.csv', sep=';')\n",
    "disp = pd.read_csv(DATA_SOURCE + 'disp.csv', sep=';')\n",
    "districts = pd.read_csv(DATA_SOURCE + 'district.csv', sep=';')\n",
    "loans = pd.read_csv(DATA_SOURCE + 'loan_dev.csv', sep=';')\n",
    "transactions = pd.read_csv(DATA_SOURCE + 'trans_dev.csv', sep=';')\n",
    "\n",
    "print(loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plenty of analysis with graphs, distributions, outliers..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Text\n",
    "\n",
    "#### Processing `account.csv`\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process account.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing `card_dev.csv`\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process card_dev.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing `client.csv`\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process client.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing `disp.csv`\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process disp.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing `district.csv`\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process district.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing loan_dev.csv\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process loan_dev.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing trans_dev.csv\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process trans_dev.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the data\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data for training\n",
    "\n",
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = loans.status.values\n",
    "independent = loans.drop('status', axis=1).values\n",
    "\n",
    "# Make sure to split by future date later...\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "        independent, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feeding the model\n",
    "\n",
    "Evaluate classification model performance with loans table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Create a Random Forest Model\n",
    "random_classifier = RandomForestClassifier(\n",
    "    n_estimators=100)\n",
    "\n",
    "# Train it with data\n",
    "random_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "predictions = random_classifier.predict(x_test)\n",
    "\n",
    "# Check the accuracy\n",
    "print(recall_score(y_test, predictions, pos_label=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Fit Naive Bayes to the training set\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "print('Recall: ', recall_score(y_test, y_pred, pos_label=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print('Recall: ', recall_score(y_test, y_pred, pos_label=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print('Recall: ', recall_score(y_test, y_pred, pos_label=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print('Recall: ', recall_score(y_test, y_pred, pos_label=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "lassifier = BernoulliRBM()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print('Recall: ', recall_score(y_test, y_pred, pos_label=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print('Recall: ', recall_score(y_test, y_pred, pos_label=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print('Recall: ', recall_score(y_test, y_pred, pos_label=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "classifiers = [ (\"cfl1\",LogisticRegression()),(\"cfl2\",SVC()),(\"cfl3\",GaussianNB()),(\"cfl4\",MultinomialNB()),(\"cfl5\",MLPClassifier())]\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "v_c = VotingClassifier(estimators= classifiers, voting=\"hard\",n_jobs = -1)\n",
    "v_c = v_c.fit(x_train,y_train)\n",
    "y_pred = v_c.predict(x_test)\n",
    "\n",
    "print('Recall: ', recall_score(y_test, y_pred, pos_label=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
